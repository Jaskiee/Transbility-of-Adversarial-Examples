{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TransAdv_pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYnn6p5f5V/B7ZEJStM/jY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2zVwSV9A52HI"},"source":["# Transferability of Adversarial Examples\n","This is a small experiment relating to the trasferability of adversarial examples, here we go."]},{"cell_type":"markdown","metadata":{"id":"6hixdTLi-sFg"},"source":["## Import Essential Packages"]},{"cell_type":"code","metadata":{"id":"j1bctZQFFelf","executionInfo":{"status":"ok","timestamp":1602759368063,"user_tz":-480,"elapsed":1242,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["import torch\n","import torchvision\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision.transforms as transforms\n","import numpy as np\n","import os\n","from google.colab import drive"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BoRPluIOYL1Y"},"source":["As the imagenet pretrained model of tensorflow can't be trained in a shor time, I implement it with **pytorch** whose cifar-10 pretrained model can be downloaded from github."]},{"cell_type":"code","metadata":{"id":"G4v2uOkyXQN9","executionInfo":{"status":"ok","timestamp":1602759368665,"user_tz":-480,"elapsed":910,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"90d1de3b-fd4e-44b3-b036-4cb32ce62535","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/adv\"\n","\n","os.chdir(path)\n","os.listdir(path)\n","\n","from cifar10_models import *"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EmSQuTLs5gVU"},"source":["## Define Constants\n","Constants like batch size."]},{"cell_type":"code","metadata":{"id":"pCNtUQdY5fsk","executionInfo":{"status":"ok","timestamp":1602759376243,"user_tz":-480,"elapsed":1795,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["batch_size = 64\n","epochs = 100"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shfyRP3S_Dxs"},"source":["## Import Dataset\n","Experiment on on CIFAR-10 implemented with pytorch."]},{"cell_type":"code","metadata":{"id":"ezqnyccGZe0F","executionInfo":{"status":"ok","timestamp":1602759414046,"user_tz":-480,"elapsed":4068,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"81bf583a-0662-4f5d-e098-89a584cd2393","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2xz5ZOAA_ADo"},"source":["## Define Models\n","Github has some pretrained cifar-10 model structures implemented with pytorch, so I directly use them. And I first try VGG-16, ResNet-50 and Inception v3."]},{"cell_type":"code","metadata":{"id":"2Au2pA6-ilJw","executionInfo":{"status":"ok","timestamp":1602334064697,"user_tz":-480,"elapsed":170052,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"5a2ab250-2698-401f-9c08-52324202d2d7","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# This setp has been done.\n","# !python cifar10_download.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100% 2.46G/2.46G [01:24<00:00, 29.0MMiB/s]\n","Download successful. Unzipping file.\n","Unzip file successful!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WN05fAnY6VAA","executionInfo":{"status":"ok","timestamp":1602759562952,"user_tz":-480,"elapsed":1259,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["del resnet50\n","del vgg16\n","del inception_v3\n","from cifar10_models import *"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKMkYupGWhmC"},"source":["# VGG16\n","vgg16 = vgg16_bn(pretrained=True)\n","# ResNet50\n","resnet50 = resnet50(pretrained=True)\n","# Inception v3\n","inception_v3 = inception_v3(pretrained=True)\n","\n","# Evaluation mode\n","vgg16.eval()\n","resnet50.eval()\n","inception_v3.eval()\n","\n","# Move the models to GPU\n","device = torch.device(\"cuda\")\n","vgg16.to(device)\n","resnet50.to(device)\n","inception_v3.to(device)\n","\n","# Check GPU\n","print(torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JyPWCKGqAyZ9"},"source":["## Train Models\n","As the models are pretrained, so the training section is omitted, or we can train for more epochs for better accuracy."]},{"cell_type":"markdown","metadata":{"id":"x8NCF15fiSSN"},"source":["## Test Model\n","Test the accuracy of the models."]},{"cell_type":"code","metadata":{"id":"T5D4LpVYBLZ5","executionInfo":{"status":"ok","timestamp":1602761314905,"user_tz":-480,"elapsed":1663,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifSNvV-aCqIY"},"source":["# evaluation mode\n","vgg16.eval()\n","resnet50.eval()\n","inception_v3.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFoDj2dciR2L","executionInfo":{"status":"ok","timestamp":1602762045321,"user_tz":-480,"elapsed":346450,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"c8a5c166-ad89-46c4-8cb0-e6bf5284c1fc","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["correct_vgg = correct_resnet = correct_inception = 0\n","total = 0\n","with torch.no_grad():\n","  for data in testloader:\n","    images, labels = data\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs_vgg = vgg16(images)\n","    outputs_resnet = resnet50(images)\n","    outputs_inception = inception_v3(images)\n","    _, predicted_vgg = torch.max(outputs_vgg.data, 1)\n","    _, predicted_resnet = torch.max(outputs_resnet.data, 1)\n","    _, predicted_inception = torch.max(outputs_inception.data, 1)\n","    total += labels.size(0)\n","    correct_vgg += (predicted_vgg == labels).sum().item()\n","    correct_resnet += (predicted_resnet == labels).sum().item()\n","    correct_inception += (predicted_inception == labels).sum().item()\n","\n","\n","print('Accuracy of the vgg16 on the 10000 test images: %d%%' % (100 * correct_vgg / total))\n","print('Accuracy of the resnet50 on the 10000 test images: %d%%' % (100 * correct_resnet / total))\n","print('Accuracy of the inception_v3 on the 10000 test images: %d%%' % (100 * correct_inception / total))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Accuracy of the vgg16 on the 10000 test images: 81%\n","Accuracy of the resnet50 on the 10000 test images: 81%\n","Accuracy of the inception_v3 on the 10000 test images: 85%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RJl7Lih3kXKK"},"source":["## Adversarial Examples\n","Here I am going to generate some adversarial examples of one specific model structure, then apply them to other models to check the transibility of adversarial examples."]},{"cell_type":"code","metadata":{"id":"gpgj4IAW1c8H","executionInfo":{"status":"ok","timestamp":1602759424683,"user_tz":-480,"elapsed":1254,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["# FGSM attack code\n","def fgsm_attack(image, epsilon, data_grad):\n","  # Collect the element-wise sign of the data gradient\n","  sign_data_grad = data_grad.sign()\n","  # Create the perturbed image by adjusting each pixel of the input image\n","  perturbed_image = image + epsilon*sign_data_grad\n","  # Adding clipping to maintain [0,1] range\n","  # perturbed_image = torch.clamp(perturbed_image, 0, 1)\n","  # Return the perturbed image\n","  return perturbed_image\n","\n","\n","def test(target_model, other_model_1, other_model_2, device, test_loader, epsilon):\n","\n","  # Accuracy counter\n","  target_correct = other_correct_1 =other_correct_2 = 0\n","  valid_examples = valid_examples_1 = valid_examples_2 = 0\n","  adv_examples = []\n","\n","  # Loop over all examples in test set\n","  for data, target in test_loader:\n","    # Send the data and label to the device\n","    data, target = data.to(device), target.to(device)\n","\n","    # Set requires_grad attribute of tensor. Important for Attack\n","    data.requires_grad = True\n","\n","    # Forward pass the data through the model\n","    output = target_model(data)\n","    other_output_1 = other_model_1(data)\n","    other_output_2 = other_model_2(data)\n","    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","    other_init_pred_1 = other_output_1.max(1, keepdim=True)[1]\n","    other_init_pred_2 = other_output_2.max(1, keepdim=True)[1]\n","\n","    # Model 1\n","    # If the initial prediction is wrong, dont bother attacking, just move on\n","    if init_pred.item() != target.item():\n","      continue\n","    else:\n","      valid_examples += 1\n","      # Calculate the loss\n","      loss = F.nll_loss(output, target)\n","      # Zero all existing gradients\n","      target_model.zero_grad()\n","      # Calculate gradients of model in backward pass\n","      loss.backward()\n","      # Collect datagrad\n","      data_grad = data.grad.data\n","      # Call FGSM Attack\n","      perturbed_data = fgsm_attack(data, epsilon, data_grad)\n","      # Re-classify the perturbed image\n","      output = target_model(perturbed_data)\n","\n","      # Check for success\n","      final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","      if final_pred.item() == target.item():\n","        target_correct += 1\n","        # Special case for saving 0 epsilon examples\n","        if (epsilon == 0) and (len(adv_examples) < 5):\n","          adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n","          adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n","        else:\n","          # Save some adv examples for visualization later\n","          if len(adv_examples) < 5:\n","            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n","            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n","\n","    # Model 2\n","    if other_init_pred_1.item() != target.item():\n","      pass\n","    else:\n","      valid_examples_1 += 1\n","      # Re-classify the perturbed image\n","      other_output_1 = other_model_1(perturbed_data)\n","\n","      # Check for success\n","      final_pred = other_output_1.max(1, keepdim=True)[1] # get the index of the max log-probability\n","      if final_pred.item() == target.item():\n","        other_correct_1 += 1\n","\n","\n","\n","    # Model 3\n","    if other_init_pred_2.item() != target.item():\n","      pass\n","    else:\n","      valid_examples_2 += 1\n","      # Re-classify the perturbed image\n","      other_output_2 = other_model_2(perturbed_data)\n","\n","      # Check for success\n","      final_pred = other_output_2.max(1, keepdim=True)[1] # get the index of the max log-probability\n","      if final_pred.item() == target.item():\n","        other_correct_2 += 1\n","   \n","\n","  # Calculate final accuracy for this epsilon\n","  final_acc = []\n","  final_acc_1 = target_correct/float(valid_examples)\n","  final_acc_2 = other_correct_1/float(valid_examples_1)\n","  final_acc_3 = other_correct_2/float(valid_examples_2)\n","    \n","  final_acc.append(final_acc_1)\n","  final_acc.append(final_acc_2)\n","  final_acc.append(final_acc_3)\n","\n","  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, target_correct, valid_examples, final_acc_1))\n","  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, other_correct_1, valid_examples_1, final_acc_2))\n","  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, other_correct_2, valid_examples_2, final_acc_3))\n","\n","  # Return the accuracy and an adversarial example\n","  return final_acc, adv_examples"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhKvPFbrZ6lV"},"source":["Here define a test loader to generate adversarial exapmles, whose batch size is 1, since the algorithm can calculate one loss for the adversarial examples once."]},{"cell_type":"code","metadata":{"id":"0_xAz6x5UoEX","executionInfo":{"status":"ok","timestamp":1602759428128,"user_tz":-480,"elapsed":1838,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}}},"source":["adv_test_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyRQWgSJaR48"},"source":["For different epsilons, the adversarial examples has different effect, here we choose a relatively large epsilons whose effect may be more manifest."]},{"cell_type":"code","metadata":{"id":"Ru4HGUcB4OXc","executionInfo":{"status":"ok","timestamp":1602760332565,"user_tz":-480,"elapsed":758158,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"f1f2fb39-ddf4-415a-80f1-b9095546d52a","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["epsilons = [0.2]\n","accuracies_vgg_based = []\n","examples_vgg = []\n","# Test VGG16\n","for eps in epsilons:\n","  acc, ex = test(vgg16, resnet50, inception_v3, device, adv_test_loader, eps)\n","  accuracies_vgg_based.append(acc)\n","  examples_vgg.append(ex)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epsilon: 0.2\tTest Accuracy = 1374 / 8139 = 0.16881680796166607\n","Epsilon: 0.2\tTest Accuracy = 1711 / 7448 = 0.22972610096670246\n","Epsilon: 0.2\tTest Accuracy = 1441 / 7674 = 0.1877769090435236\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0x8bcKkzQNKa","executionInfo":{"status":"ok","timestamp":1602763023602,"user_tz":-480,"elapsed":730135,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"c1a6afbe-b4a6-407a-e9f8-ff42af02a2a9","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["accuracies_resnet_based = []\n","examples_resnet = []\n","# Test ResNet50\n","for eps in epsilons:\n","    acc, ex = test(resnet50, vgg16, inception_v3, device, adv_test_loader, eps)\n","    accuracies_resnet_based.append(acc)\n","    examples_resnet.append(ex)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epsilon: 0.2\tTest Accuracy = 1538 / 8133 = 0.18910611090618468\n","Epsilon: 0.2\tTest Accuracy = 1465 / 7448 = 0.19669709989258863\n","Epsilon: 0.2\tTest Accuracy = 1460 / 7661 = 0.19057564286646653\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wEu34pFggDLC","executionInfo":{"status":"ok","timestamp":1602761137158,"user_tz":-480,"elapsed":1560439,"user":{"displayName":"谢斯棋","photoUrl":"","userId":"13460657872157698438"}},"outputId":"6f25bf35-1531-4ff8-b2f6-c880dd136bfc","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["accuracies_inception_based = []\n","examples_inception = []\n","# Test Inception v3\n","for eps in epsilons:\n","    acc, ex = test(inception_v3, vgg16, resnet50, device, adv_test_loader, eps)\n","    accuracies_inception_based.append(acc)\n","    examples_inception.append(ex)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epsilon: 0.2\tTest Accuracy = 1793 / 8588 = 0.20877969259431764\n","Epsilon: 0.2\tTest Accuracy = 1561 / 7674 = 0.20341412561897315\n","Epsilon: 0.2\tTest Accuracy = 2000 / 7661 = 0.26106252447461165\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ofLbeH_H0XhB"},"source":["## Result"]},{"cell_type":"markdown","metadata":{"id":"83CEdaPDNWLp"},"source":["| Data Type / Accuracy/ Model Structure | VGG-16 | ResNet-50 |  Inception v3 |\n","|                 :----:                | :----: |   :----:  | :----:|\n","| Normal Data                           |   81%  |    81%    | 85% |\n","| VGG-16 based Adversarial Data         |1374 / 8139 = 16.88%|1711 / 7448 = 22.97%|1441 / 7674 = 18.78%|\n","| ResNet-50 based Adversarial Data      |1465 / 7448 = 19.67%|1538 / 8133 = 18.91%|1460 / 7661 = 19.06%|\n","| Inception v3 based AdAdversarial Data |1561 / 7674 = 20.34%|2000 / 7661 = 26.11%|1793 / 8588 = 20.88%|"]}]}