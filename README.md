# Transferability-of-Adversarial-Examples
This is a small experiment to check the transferability of adversarial examples.

I used different model structure to generate adversarial examples, by implementing FGSM method, then used different networks to predict them on the same task. I chose three tpytical network structures in image classification (CIFAR-10), including VGG-16, ResNet-50 and Inception v3. The result shows that the adversarial examples generated by one specific network structure do can influence the effect of other models in different archetechtures on the same task.

I then refered to some papers ([Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/pdf/1905.02175.pdf), [High-frequency Component Helps Explain the Generalization of Convolutional Neural Networks](https://arxiv.org/pdf/1905.13545.pdf)) and they gave the explainations that, the transferability of different network showed that they utilized similar features of the images to make the prediction, and a large portion of these features were imperceptible to humam, these imperceptible features were the real changes of the adversarial examples, and theses features were usually in high-frequency, which were difficult for people to perceive but well utilized by the networks.

This work was first implemented in tensorflow, since I couldn't find cifar-10 pretrained models in tensorflow and retraining the models can really spend lots of time, so I implemented in pytorch with the help of [pytorch tutorial](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html) and repo [PyTorch models trained on CIFAR-10 dataset](https://github.com/huyvnphan/PyTorch_CIFAR10), thanks to these great works.

Here is the result:

| Data Type / Accuracy/ Model Structure |       VGG-16       |      ResNet-50     |    Inception v3    |
|                 :----:                |       :----:       |       :----:       |       :----:       |
| Normal Data                           |         81%        |         81%        |         85%        |
| VGG-16 based Adversarial Data         |1374 / 8139 = 16.88%|1711 / 7448 = 22.97%|1441 / 7674 = 18.78%|
| ResNet-50 based Adversarial Data      |1465 / 7448 = 19.67%|1538 / 8133 = 18.91%|1460 / 7661 = 19.06%|
| Inception v3 based AdAdversarial Data |1561 / 7674 = 20.34%|2000 / 7661 = 26.11%|1793 / 8588 = 20.88%|
